{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb296c0d",
   "metadata": {},
   "source": [
    "# Training Data Preparation: Triple-Barrier (Bollinger Mean Reversion)\n",
    "\n",
    "This notebook prepares the final training dataset for the triple-barrier approach with Bollinger Band mean reversion strategy by:\n",
    "\n",
    "1. **Loading features** from `features_triple_barrier.csv`\n",
    "2. **Loading labels** from triple-barrier events CSV (generated by meta_labeling.ipynb)\n",
    "3. **Merging** features with labels on timestamp\n",
    "4. **Computing sample weights** using concurrency and return attribution\n",
    "5. **Preprocessing features** with MinMax normalization\n",
    "6. **Time-based train/test split** (no shuffling to preserve temporal order)\n",
    "7. **Saving ready-to-use datasets** for model training\n",
    "\n",
    "**Strategy Context:**\n",
    "- Primary model: Bollinger Band mean reversion (window=20, num_std=2.0)\n",
    "- Entry filter: CUSUM filter on volatility\n",
    "- Triple-barrier settings: pt_sl=[1, 2], vertical_barrier=50 bars\n",
    "- Can be changed to MA crossover later for comparison with trend-scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da01602d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d649a",
   "metadata": {},
   "source": [
    "## 1. Load Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6fe72a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features from data/features_triple_barrier.csv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Features loaded: (332916, 51)\n",
      "  Date range: 2022-09-02 00:05:00 to 2025-10-31 23:00:00\n",
      "  Columns: 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_spread</th>\n",
       "      <th>bb_bandwidth</th>\n",
       "      <th>bb_percentage</th>\n",
       "      <th>returns</th>\n",
       "      <th>returns_5</th>\n",
       "      <th>returns_10</th>\n",
       "      <th>returns_1_lag_1</th>\n",
       "      <th>returns_5_lag_1</th>\n",
       "      <th>returns_10_lag_1</th>\n",
       "      <th>returns_1_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi</th>\n",
       "      <th>stoch_rsi_k</th>\n",
       "      <th>stoch_rsi_d</th>\n",
       "      <th>adx</th>\n",
       "      <th>adxr</th>\n",
       "      <th>dmp</th>\n",
       "      <th>dmn</th>\n",
       "      <th>dm_net</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_hist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:05:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:10:00</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:15:00</th>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rel_spread  bb_bandwidth  bb_percentage   returns  \\\n",
       "time                                                                     \n",
       "2022-09-02 00:05:00    0.000000           0.0            0.0  0.000000   \n",
       "2022-09-02 00:10:00    0.000573           0.0            0.0  0.000000   \n",
       "2022-09-02 00:15:00    0.000221           0.0            0.0  0.000065   \n",
       "\n",
       "                     returns_5  returns_10  returns_1_lag_1  returns_5_lag_1  \\\n",
       "time                                                                           \n",
       "2022-09-02 00:05:00        0.0         0.0         0.000000              0.0   \n",
       "2022-09-02 00:10:00        0.0         0.0         0.000000              0.0   \n",
       "2022-09-02 00:15:00        0.0         0.0         0.000065              0.0   \n",
       "\n",
       "                     returns_10_lag_1  returns_1_lag_2  ...  rsi  stoch_rsi_k  \\\n",
       "time                                                    ...                     \n",
       "2022-09-02 00:05:00               0.0              0.0  ...  0.0          0.0   \n",
       "2022-09-02 00:10:00               0.0              0.0  ...  0.0          0.0   \n",
       "2022-09-02 00:15:00               0.0              0.0  ...  0.0          0.0   \n",
       "\n",
       "                     stoch_rsi_d  adx  adxr  dmp  dmn  dm_net  macd  macd_hist  \n",
       "time                                                                            \n",
       "2022-09-02 00:05:00          0.0  0.0   0.0  0.0  0.0     0.0   0.0        0.0  \n",
       "2022-09-02 00:10:00          0.0  0.0   0.0  0.0  0.0     0.0   0.0        0.0  \n",
       "2022-09-02 00:15:00          0.0  0.0   0.0  0.0  0.0     0.0   0.0        0.0  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load features\n",
    "features_file = 'data/features_triple_barrier.csv'\n",
    "print(f\"Loading features from {features_file}...\")\n",
    "features = pd.read_csv(features_file, index_col=0, parse_dates=True)\n",
    "\n",
    "print(f\"✓ Features loaded: {features.shape}\")\n",
    "print(f\"  Date range: {features.index[0]} to {features.index[-1]}\")\n",
    "print(f\"  Columns: {len(features.columns)}\")\n",
    "features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57cca239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels from EURUSD_triple_barrier_events_filtered.csv...\n",
      "✓ Labels loaded: (10270, 5)\n",
      "  Date range: 2022-09-05 00:10:00 to 2025-10-31 21:30:00\n",
      "  Columns: ['t1', 'trgt', 'ret', 'bin', 'side']\n",
      "\n",
      "Label distribution (Meta-Labeling):\n",
      "  SKIP_TRADE      ( 0):  3,891 (37.89%)\n",
      "  TAKE_TRADE      ( 1):  6,379 (62.11%)\n",
      "\n",
      "  Interpretation:\n",
      "    1 (TAKE_TRADE): Primary strategy was correct (positive return)\n",
      "    0 (SKIP_TRADE): Primary strategy was incorrect (negative/zero return)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>trgt</th>\n",
       "      <th>ret</th>\n",
       "      <th>bin</th>\n",
       "      <th>side</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-05 00:10:00</th>\n",
       "      <td>2022-09-05 01:20:00</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 05:20:00</th>\n",
       "      <td>2022-09-05 06:00:00</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 05:25:00</th>\n",
       "      <td>2022-09-05 05:55:00</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      t1      trgt       ret  bin  side\n",
       "time                                                                   \n",
       "2022-09-05 00:10:00  2022-09-05 01:20:00  0.000848 -0.002563    0     1\n",
       "2022-09-05 05:20:00  2022-09-05 06:00:00  0.000471  0.000505    1     1\n",
       "2022-09-05 05:25:00  2022-09-05 05:55:00  0.000647  0.000697    1     1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and load the triple-barrier events file\n",
    "data_dir = Path('data')\n",
    "label_files = list(data_dir.glob('EURUSD_triple_barrier_events_filtered.csv'))\n",
    "\n",
    "if not label_files:\n",
    "    raise FileNotFoundError(\"No triple-barrier events file found! Run meta_labeling.ipynb first.\")\n",
    "\n",
    "# Use the most recent file if multiple exist\n",
    "labels_file = sorted(label_files)[-1]\n",
    "print(f\"Loading labels from {labels_file.name}...\")\n",
    "labels = pd.read_csv(labels_file, index_col=0, parse_dates=True)\n",
    "\n",
    "print(f\"✓ Labels loaded: {labels.shape}\")\n",
    "print(f\"  Date range: {labels.index[0]} to {labels.index[-1]}\")\n",
    "print(f\"  Columns: {list(labels.columns)}\")\n",
    "print(f\"\\nLabel distribution (Meta-Labeling):\")\n",
    "if 'bin' in labels.columns:\n",
    "    label_dist = labels['bin'].value_counts().sort_index()\n",
    "    for label, count in label_dist.items():\n",
    "        pct = count / len(labels) * 100\n",
    "        label_name = {0: 'SKIP_TRADE', 1: 'TAKE_TRADE'}.get(label, 'UNKNOWN')\n",
    "        print(f\"  {label_name:15s} ({label:2d}): {count:6,} ({pct:5.2f}%)\")\n",
    "    print(f\"\\n  Interpretation:\")\n",
    "    print(f\"    1 (TAKE_TRADE): Primary strategy was correct (positive return)\")\n",
    "    print(f\"    0 (SKIP_TRADE): Primary strategy was incorrect (negative/zero return)\")\n",
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5300d0",
   "metadata": {},
   "source": [
    "## 2. Merge Features with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "154cedfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging features with labels...\n",
      "  Features: 332,916 rows\n",
      "  Labels: 10,270 rows\n",
      "\n",
      "✓ Merged dataset: (10270, 56)\n",
      "  Date range: 2022-09-05 00:10:00 to 2025-10-31 21:30:00\n",
      "  Lost 322,646 observations due to missing labels\n",
      "\n",
      "Missing values check:\n",
      "  Features: 0\n",
      "  Labels (bin): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_spread</th>\n",
       "      <th>bb_bandwidth</th>\n",
       "      <th>bb_percentage</th>\n",
       "      <th>returns</th>\n",
       "      <th>returns_5</th>\n",
       "      <th>returns_10</th>\n",
       "      <th>returns_1_lag_1</th>\n",
       "      <th>returns_5_lag_1</th>\n",
       "      <th>returns_10_lag_1</th>\n",
       "      <th>returns_1_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>dmp</th>\n",
       "      <th>dmn</th>\n",
       "      <th>dm_net</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>t1</th>\n",
       "      <th>trgt</th>\n",
       "      <th>ret</th>\n",
       "      <th>bin</th>\n",
       "      <th>side</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-05 00:10:00</th>\n",
       "      <td>0.000151</td>\n",
       "      <td>2.229845e-14</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.543471e-22</td>\n",
       "      <td>2.554528e-22</td>\n",
       "      <td>9.889432e-23</td>\n",
       "      <td>-9.992007e-16</td>\n",
       "      <td>3.944305e-31</td>\n",
       "      <td>2022-09-05 01:20:00</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 05:20:00</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.061910e-01</td>\n",
       "      <td>-0.048282</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060345e-03</td>\n",
       "      <td>1.529010e-03</td>\n",
       "      <td>-4.686647e-04</td>\n",
       "      <td>-9.214245e-05</td>\n",
       "      <td>-4.874923e-05</td>\n",
       "      <td>2022-09-05 06:00:00</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 05:25:00</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.383139e-01</td>\n",
       "      <td>-0.211446</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>...</td>\n",
       "      <td>9.846060e-04</td>\n",
       "      <td>1.869795e-03</td>\n",
       "      <td>-8.851887e-04</td>\n",
       "      <td>-1.614933e-04</td>\n",
       "      <td>-9.448007e-05</td>\n",
       "      <td>2022-09-05 05:55:00</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rel_spread  bb_bandwidth  bb_percentage   returns  \\\n",
       "time                                                                     \n",
       "2022-09-05 00:10:00    0.000151  2.229845e-14      -4.500000  0.000000   \n",
       "2022-09-05 05:20:00    0.000010  1.061910e-01      -0.048282 -0.000282   \n",
       "2022-09-05 05:25:00    0.000010  1.383139e-01      -0.211446 -0.000444   \n",
       "\n",
       "                     returns_5  returns_10  returns_1_lag_1  returns_5_lag_1  \\\n",
       "time                                                                           \n",
       "2022-09-05 00:10:00   0.000000    0.000000         0.000000         0.000000   \n",
       "2022-09-05 05:20:00  -0.000131   -0.000063        -0.000282         0.000002   \n",
       "2022-09-05 05:25:00  -0.000204   -0.000101        -0.000444        -0.000040   \n",
       "\n",
       "                     returns_10_lag_1  returns_1_lag_2  ...           dmp  \\\n",
       "time                                                    ...                 \n",
       "2022-09-05 00:10:00          0.000000         0.000000  ...  3.543471e-22   \n",
       "2022-09-05 05:20:00          0.000017        -0.000292  ...  1.060345e-03   \n",
       "2022-09-05 05:25:00          0.000019        -0.000282  ...  9.846060e-04   \n",
       "\n",
       "                              dmn        dm_net          macd     macd_hist  \\\n",
       "time                                                                          \n",
       "2022-09-05 00:10:00  2.554528e-22  9.889432e-23 -9.992007e-16  3.944305e-31   \n",
       "2022-09-05 05:20:00  1.529010e-03 -4.686647e-04 -9.214245e-05 -4.874923e-05   \n",
       "2022-09-05 05:25:00  1.869795e-03 -8.851887e-04 -1.614933e-04 -9.448007e-05   \n",
       "\n",
       "                                      t1      trgt       ret  bin  side  \n",
       "time                                                                     \n",
       "2022-09-05 00:10:00  2022-09-05 01:20:00  0.000848 -0.002563    0     1  \n",
       "2022-09-05 05:20:00  2022-09-05 06:00:00  0.000471  0.000505    1     1  \n",
       "2022-09-05 05:25:00  2022-09-05 05:55:00  0.000647  0.000697    1     1  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge on timestamp (inner join to keep only observations with both features and labels)\n",
    "print(\"Merging features with labels...\")\n",
    "print(f\"  Features: {len(features):,} rows\")\n",
    "print(f\"  Labels: {len(labels):,} rows\")\n",
    "\n",
    "# Inner join on index (timestamp)\n",
    "data = features.join(labels, how='inner', rsuffix='_label')\n",
    "\n",
    "print(f\"\\n✓ Merged dataset: {data.shape}\")\n",
    "print(f\"  Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "print(f\"  Lost {len(features) - len(data):,} observations due to missing labels\")\n",
    "\n",
    "# Verify no missing values in critical columns\n",
    "print(f\"\\nMissing values check:\")\n",
    "print(f\"  Features: {data[features.columns].isnull().sum().sum()}\")\n",
    "print(f\"  Labels (bin): {data['bin'].isnull().sum()}\")\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdefc01",
   "metadata": {},
   "source": [
    "## 3. Prepare Features, Labels, and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74e4fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET COMPOSITION\n",
      "================================================================================\n",
      "Features (X): (10270, 51)\n",
      "Labels (y): (10270,)\n",
      "Label metadata: (10270, 4)\n",
      "  Metadata columns: ['t1', 'trgt', 'ret', 'side']\n",
      "\n",
      "Label distribution (Meta-Labeling):\n",
      "  SKIP_TRADE      ( 0):  3,891 (37.89%)\n",
      "  TAKE_TRADE      ( 1):  6,379 (62.11%)\n",
      "\n",
      "Meta-Label Interpretation:\n",
      "  1 (TAKE_TRADE): Primary strategy was correct → take the trade\n",
      "  0 (SKIP_TRADE): Primary strategy was incorrect → skip the trade\n",
      "\n",
      "Return statistics:\n",
      "  Mean: 0.000045\n",
      "  Median: 0.000404\n",
      "  Std: 0.001530\n",
      "  Min: -0.012612\n",
      "  Max: 0.010656\n",
      "\n",
      "DATASET COMPOSITION\n",
      "================================================================================\n",
      "Features (X): (10270, 51)\n",
      "Labels (y): (10270,)\n",
      "Label metadata: (10270, 4)\n",
      "  Metadata columns: ['t1', 'trgt', 'ret', 'side']\n",
      "\n",
      "Label distribution (Meta-Labeling):\n",
      "  SKIP_TRADE      ( 0):  3,891 (37.89%)\n",
      "  TAKE_TRADE      ( 1):  6,379 (62.11%)\n",
      "\n",
      "Meta-Label Interpretation:\n",
      "  1 (TAKE_TRADE): Primary strategy was correct → take the trade\n",
      "  0 (SKIP_TRADE): Primary strategy was incorrect → skip the trade\n",
      "\n",
      "Return statistics:\n",
      "  Mean: 0.000045\n",
      "  Median: 0.000404\n",
      "  Std: 0.001530\n",
      "  Min: -0.012612\n",
      "  Max: 0.010656\n"
     ]
    }
   ],
   "source": [
    "# Separate features, labels, and metadata\n",
    "feature_cols = features.columns.tolist()\n",
    "X = data[feature_cols].copy()\n",
    "y = data['bin'].copy()\n",
    "\n",
    "# Extract metadata columns (may vary depending on triple_barrier output)\n",
    "metadata_cols = [col for col in labels.columns if col != 'bin']\n",
    "label_metadata = data[metadata_cols].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET COMPOSITION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Labels (y): {y.shape}\")\n",
    "print(f\"Label metadata: {label_metadata.shape}\")\n",
    "print(f\"  Metadata columns: {list(label_metadata.columns)}\")\n",
    "\n",
    "print(f\"\\nLabel distribution (Meta-Labeling):\")\n",
    "label_counts = y.value_counts().sort_index()\n",
    "for label, count in label_counts.items():\n",
    "    pct = count / len(y) * 100\n",
    "    label_name = {0: 'SKIP_TRADE', 1: 'TAKE_TRADE'}.get(label, 'UNKNOWN')\n",
    "    print(f\"  {label_name:15s} ({label:2d}): {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nMeta-Label Interpretation:\")\n",
    "print(f\"  1 (TAKE_TRADE): Primary strategy was correct → take the trade\")\n",
    "print(f\"  0 (SKIP_TRADE): Primary strategy was incorrect → skip the trade\")\n",
    "\n",
    "# Check if return information is available\n",
    "if 'ret' in label_metadata.columns:\n",
    "    print(f\"\\nReturn statistics:\")\n",
    "    print(f\"  Mean: {label_metadata['ret'].mean():.6f}\")\n",
    "    print(f\"  Median: {label_metadata['ret'].median():.6f}\")\n",
    "    print(f\"  Std: {label_metadata['ret'].std():.6f}\")\n",
    "    print(f\"  Min: {label_metadata['ret'].min():.6f}\")\n",
    "    print(f\"  Max: {label_metadata['ret'].max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e86a7",
   "metadata": {},
   "source": [
    "## 4. Feature Normalization (MinMax Scaling)\n",
    "\n",
    "**Important:** We normalize features to [0, 1] range to:\n",
    "- Ensure all features contribute equally to the model\n",
    "- Improve convergence for tree-based models\n",
    "- Make feature importance more interpretable\n",
    "\n",
    "**Note:** We fit the scaler on training data and transform both train and test to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10cc0b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature statistics check:\n",
      "  Features with inf: 0\n",
      "  Features with NaN: 0\n",
      "  ✓ No constant columns detected\n",
      "\n",
      "Final feature count: 51\n"
     ]
    }
   ],
   "source": [
    "# Check for any extreme values or issues before normalization\n",
    "print(\"Feature statistics check:\")\n",
    "print(f\"  Features with inf: {np.isinf(X).sum().sum()}\")\n",
    "print(f\"  Features with NaN: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# Check for constant columns (would cause issues in normalization)\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(f\"\\n⚠ WARNING - Constant columns detected ({len(constant_cols)}): {constant_cols}\")\n",
    "    print(f\"  These will be removed before normalization\")\n",
    "    X = X.drop(columns=constant_cols)\n",
    "    feature_cols = X.columns.tolist()\n",
    "else:\n",
    "    print(f\"  ✓ No constant columns detected\")\n",
    "\n",
    "print(f\"\\nFinal feature count: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e05352",
   "metadata": {},
   "source": [
    "## 5. Time-Based Train/Test Split\n",
    "\n",
    "**Critical for time-series:**\n",
    "- No shuffling (preserves temporal order)\n",
    "- Train on earlier data, test on later data\n",
    "- Simulates real-world deployment scenario\n",
    "- Standard split: 70% train, 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c2e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAIN/TEST SPLIT (Time-Based, No Shuffling)\n",
      "================================================================================\n",
      "Split ratio: 70% train / 30% test\n",
      "Split index: 7,188\n",
      "\n",
      "Train set:\n",
      "  Shape: (7188, 51)\n",
      "  Date range: 2022-09-05 00:10:00 to 2024-12-23 03:10:00\n",
      "  Label distribution:\n",
      "    SKIP_TRADE      ( 0):  2,696 (37.51%)\n",
      "    TAKE_TRADE      ( 1):  4,492 (62.49%)\n",
      "\n",
      "Test set:\n",
      "  Shape: (3082, 51)\n",
      "  Date range: 2024-12-23 03:50:00 to 2025-10-31 21:30:00\n",
      "  Label distribution:\n",
      "    SKIP_TRADE      ( 0):  1,195 (38.77%)\n",
      "    TAKE_TRADE      ( 1):  1,887 (61.23%)\n"
     ]
    }
   ],
   "source": [
    "# Time-based split (70/30)\n",
    "split_ratio = 0.70\n",
    "split_idx = int(len(data) * split_ratio)\n",
    "\n",
    "# Split data\n",
    "X_train = X.iloc[:split_idx].copy()\n",
    "X_test = X.iloc[split_idx:].copy()\n",
    "y_train = y.iloc[:split_idx].copy()\n",
    "y_test = y.iloc[split_idx:].copy()\n",
    "\n",
    "metadata_train = label_metadata.iloc[:split_idx].copy()\n",
    "metadata_test = label_metadata.iloc[split_idx:].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAIN/TEST SPLIT (Time-Based, No Shuffling)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Split ratio: {split_ratio:.0%} train / {1-split_ratio:.0%} test\")\n",
    "print(f\"Split index: {split_idx:,}\")\n",
    "print(f\"\\nTrain set:\")\n",
    "print(f\"  Shape: {X_train.shape}\")\n",
    "print(f\"  Date range: {X_train.index[0]} to {X_train.index[-1]}\")\n",
    "print(f\"  Label distribution:\")\n",
    "for label, count in y_train.value_counts().sort_index().items():\n",
    "    pct = count / len(y_train) * 100\n",
    "    label_name = {0: 'SKIP_TRADE', 1: 'TAKE_TRADE'}.get(label, 'UNKNOWN')\n",
    "    print(f\"    {label_name:15s} ({label:2d}): {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Shape: {X_test.shape}\")\n",
    "print(f\"  Date range: {X_test.index[0]} to {X_test.index[-1]}\")\n",
    "print(f\"  Label distribution:\")\n",
    "for label, count in y_test.value_counts().sort_index().items():\n",
    "    pct = count / len(y_test) * 100\n",
    "    label_name = {0: 'SKIP_TRADE', 1: 'TAKE_TRADE'}.get(label, 'UNKNOWN')\n",
    "    print(f\"    {label_name:15s} ({label:2d}): {count:6,} ({pct:5.2f}%)\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a87b41",
   "metadata": {},
   "source": [
    "## 6. Normalize Features with MinMax Scaler\n",
    "\n",
    "**Fit on train, transform both train and test** to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "361ba804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MinMaxScaler on training data...\n",
      "Transforming features to [0, 1] range...\n",
      "✓ Normalization complete\n",
      "\n",
      "Scaled feature statistics (train):\n",
      "  Min: 0.000000\n",
      "  Max: 1.000000\n",
      "  Mean: 0.373208\n",
      "  Std: 0.084831\n",
      "\n",
      "Scaled feature statistics (test):\n",
      "  Min: -0.038140\n",
      "  Max: 1.531887\n",
      "  Mean: 0.378500\n",
      "  Std: 0.082704\n",
      "\n",
      "Data quality check (post-scaling):\n",
      "  Train - NaN: 0, Inf: 0\n",
      "  Test - NaN: 0, Inf: 0\n",
      "\n",
      "Transforming features to [0, 1] range...\n",
      "✓ Normalization complete\n",
      "\n",
      "Scaled feature statistics (train):\n",
      "  Min: 0.000000\n",
      "  Max: 1.000000\n",
      "  Mean: 0.373208\n",
      "  Std: 0.084831\n",
      "\n",
      "Scaled feature statistics (test):\n",
      "  Min: -0.038140\n",
      "  Max: 1.531887\n",
      "  Mean: 0.378500\n",
      "  Std: 0.082704\n",
      "\n",
      "Data quality check (post-scaling):\n",
      "  Train - NaN: 0, Inf: 0\n",
      "  Test - NaN: 0, Inf: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit scaler on training data only\n",
    "print(\"Fitting MinMaxScaler on training data...\")\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both train and test\n",
    "print(\"Transforming features to [0, 1] range...\")\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    index=X_test.index,\n",
    "    columns=X_test.columns\n",
    ")\n",
    "\n",
    "print(f\"✓ Normalization complete\")\n",
    "print(f\"\\nScaled feature statistics (train):\")\n",
    "print(f\"  Min: {X_train_scaled.min().min():.6f}\")\n",
    "print(f\"  Max: {X_train_scaled.max().max():.6f}\")\n",
    "print(f\"  Mean: {X_train_scaled.mean().mean():.6f}\")\n",
    "print(f\"  Std: {X_train_scaled.std().mean():.6f}\")\n",
    "\n",
    "print(f\"\\nScaled feature statistics (test):\")\n",
    "print(f\"  Min: {X_test_scaled.min().min():.6f}\")\n",
    "print(f\"  Max: {X_test_scaled.max().max():.6f}\")\n",
    "print(f\"  Mean: {X_test_scaled.mean().mean():.6f}\")\n",
    "print(f\"  Std: {X_test_scaled.std().mean():.6f}\")\n",
    "\n",
    "# Verify no NaN or inf after scaling\n",
    "print(f\"\\nData quality check (post-scaling):\")\n",
    "print(f\"  Train - NaN: {X_train_scaled.isnull().sum().sum()}, Inf: {np.isinf(X_train_scaled).sum().sum()}\")\n",
    "print(f\"  Test - NaN: {X_test_scaled.isnull().sum().sum()}, Inf: {np.isinf(X_test_scaled).sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af46cb",
   "metadata": {},
   "source": [
    "## 7. Save Processed Datasets\n",
    "\n",
    "Save **ready-to-use** datasets for model training:\n",
    "- Features (normalized)\n",
    "- Labels\n",
    "- Sample weights (uniform for now, can be updated later)\n",
    "- Label metadata (for analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50cb3840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING PROCESSED DATASETS\n",
      "================================================================================\n",
      "Train set saved:\n",
      "  Features: X_train_triple_barrier_20251102_185226.csv\n",
      "  Labels: y_train_triple_barrier_20251102_185226.csv\n",
      "  Metadata: metadata_train_triple_barrier_20251102_185226.csv\n",
      "Train set saved:\n",
      "  Features: X_train_triple_barrier_20251102_185226.csv\n",
      "  Labels: y_train_triple_barrier_20251102_185226.csv\n",
      "  Metadata: metadata_train_triple_barrier_20251102_185226.csv\n",
      "\n",
      "Test set saved:\n",
      "  Features: X_test_triple_barrier_20251102_185226.csv\n",
      "  Labels: y_test_triple_barrier_20251102_185226.csv\n",
      "  Metadata: metadata_test_triple_barrier_20251102_185226.csv\n",
      "\n",
      "Feature names: feature_names_triple_barrier_20251102_185226.txt\n",
      "\n",
      "================================================================================\n",
      "✓ ALL DATASETS SAVED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "Datasets ready for model training in: data\\training\n",
      "\n",
      "Next steps:\n",
      "  1. Compute concurrency weights (optional) using concurrency_weights.ipynb\n",
      "  2. Train Random Forest with weighted samples in models.ipynb\n",
      "  3. Compare with trend-scanning approach\n",
      "\n",
      "Note: Currently using Bollinger mean reversion strategy\n",
      "      Can change to MA crossover in meta_labeling.ipynb for comparison\n",
      "\n",
      "Test set saved:\n",
      "  Features: X_test_triple_barrier_20251102_185226.csv\n",
      "  Labels: y_test_triple_barrier_20251102_185226.csv\n",
      "  Metadata: metadata_test_triple_barrier_20251102_185226.csv\n",
      "\n",
      "Feature names: feature_names_triple_barrier_20251102_185226.txt\n",
      "\n",
      "================================================================================\n",
      "✓ ALL DATASETS SAVED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "Datasets ready for model training in: data\\training\n",
      "\n",
      "Next steps:\n",
      "  1. Compute concurrency weights (optional) using concurrency_weights.ipynb\n",
      "  2. Train Random Forest with weighted samples in models.ipynb\n",
      "  3. Compare with trend-scanning approach\n",
      "\n",
      "Note: Currently using Bollinger mean reversion strategy\n",
      "      Can change to MA crossover in meta_labeling.ipynb for comparison\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('data/training')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING PROCESSED DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save train set\n",
    "train_features_file = output_dir / f'X_train_triple_barrier_{timestamp}.csv'\n",
    "train_labels_file = output_dir / f'y_train_triple_barrier_{timestamp}.csv'\n",
    "train_metadata_file = output_dir / f'metadata_train_triple_barrier_{timestamp}.csv'\n",
    "\n",
    "X_train_scaled.to_csv(train_features_file)\n",
    "y_train.to_csv(train_labels_file, header=True)\n",
    "\n",
    "metadata_train.to_csv(train_metadata_file)\n",
    "\n",
    "print(f\"Train set saved:\")\n",
    "print(f\"  Features: {train_features_file.name}\")\n",
    "print(f\"  Labels: {train_labels_file.name}\")\n",
    "print(f\"  Metadata: {train_metadata_file.name}\")\n",
    "\n",
    "# Save test set\n",
    "test_features_file = output_dir / f'X_test_triple_barrier_{timestamp}.csv'\n",
    "test_labels_file = output_dir / f'y_test_triple_barrier_{timestamp}.csv'\n",
    "test_metadata_file = output_dir / f'metadata_test_triple_barrier_{timestamp}.csv'\n",
    "\n",
    "X_test_scaled.to_csv(test_features_file)\n",
    "y_test.to_csv(test_labels_file, header=True)\n",
    "\n",
    "metadata_test.to_csv(test_metadata_file)\n",
    "\n",
    "print(f\"\\nTest set saved:\")\n",
    "print(f\"  Features: {test_features_file.name}\")\n",
    "print(f\"  Labels: {test_labels_file.name}\")\n",
    "print(f\"  Metadata: {test_metadata_file.name}\")\n",
    "\n",
    "# Save feature names for reference\n",
    "feature_names_file = output_dir / f'feature_names_triple_barrier_{timestamp}.txt'\n",
    "with open(feature_names_file, 'w') as f:\n",
    "    f.write(\"Triple-Barrier Feature Names (Bollinger Mean Reversion)\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    for i, col in enumerate(X_train_scaled.columns, 1):\n",
    "        f.write(f\"{i}. {col}\\n\")\n",
    "\n",
    "print(f\"\\nFeature names: {feature_names_file.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ ALL DATASETS SAVED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDatasets ready for model training in: {output_dir}\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Compute concurrency weights (optional) using concurrency_weights.ipynb\")\n",
    "print(f\"  2. Train Random Forest with weighted samples in models.ipynb\")\n",
    "print(f\"  3. Compare with trend-scanning approach\")\n",
    "print(f\"\\nNote: Currently using Bollinger mean reversion strategy\")\n",
    "print(f\"      Can change to MA crossover in meta_labeling.ipynb for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8fcd3",
   "metadata": {},
   "source": [
    "## 8. Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09f81a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Train Set:\n",
      "  Observations: 7,188\n",
      "  Features: 51\n",
      "  Date range: 2022-09-05 00:10:00 to 2024-12-23 03:10:00\n",
      "  Label distribution:\n",
      "    SKIP_TRADE: 2,696 (37.51%)\n",
      "    TAKE_TRADE: 4,492 (62.49%)\n",
      "\n",
      "Test Set:\n",
      "  Observations: 3,082\n",
      "  Features: 51\n",
      "  Date range: 2024-12-23 03:50:00 to 2025-10-31 21:30:00\n",
      "  Label distribution:\n",
      "    SKIP_TRADE: 1,195 (38.77%)\n",
      "    TAKE_TRADE: 1,887 (61.23%)\n",
      "\n",
      "Feature Normalization:\n",
      "  Method: MinMaxScaler\n",
      "  Range: [0, 1]\n",
      "  Fitted on: Train set only\n",
      "  Applied to: Both train and test\n",
      "\n",
      "Primary Strategy:\n",
      "  Strategy: Bollinger Band Mean Reversion\n",
      "  Window: 20, Std: 2.0\n",
      "  Entry filter: Optional CUSUM filter on volatility\n",
      "  Triple-barrier: pt_sl=[1, 2], vertical_barrier=50 bars\n",
      "\n",
      "Meta-Labeling Approach:\n",
      "  1 (TAKE_TRADE): ML agrees with primary strategy → execute trade\n",
      "  0 (SKIP_TRADE): ML disagrees with primary strategy → skip trade\n",
      "  Purpose: Filter primary strategy signals to improve performance\n",
      "\n",
      "✓ Data preparation complete!\n",
      "✓ Ready for Random Forest training with meta-labels\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  Observations: {len(X_train_scaled):,}\")\n",
    "print(f\"  Features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"  Date range: {X_train_scaled.index[0]} to {X_train_scaled.index[-1]}\")\n",
    "print(f\"  Label distribution:\")\n",
    "for label, count in y_train.value_counts().sort_index().items():\n",
    "    pct = count / len(y_train) * 100\n",
    "    label_name = {0: 'SKIP_TRADE', 1: 'TAKE_TRADE'}.get(label, 'UNKNOWN')\n",
    "    print(f\"    {label_name}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  Observations: {len(X_test_scaled):,}\")\n",
    "print(f\"  Features: {X_test_scaled.shape[1]}\")\n",
    "print(f\"  Date range: {X_test_scaled.index[0]} to {X_test_scaled.index[-1]}\")\n",
    "print(f\"  Label distribution:\")\n",
    "for label, count in y_test.value_counts().sort_index().items():\n",
    "    pct = count / len(y_test) * 100\n",
    "    label_name = {0: 'SKIP_TRADE', 1: 'TAKE_TRADE'}.get(label, 'UNKNOWN')\n",
    "    print(f\"    {label_name}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nFeature Normalization:\")\n",
    "print(f\"  Method: MinMaxScaler\")\n",
    "print(f\"  Range: [0, 1]\")\n",
    "print(f\"  Fitted on: Train set only\")\n",
    "print(f\"  Applied to: Both train and test\")\n",
    "\n",
    "print(f\"\\nPrimary Strategy:\")\n",
    "print(f\"  Strategy: Bollinger Band Mean Reversion\")\n",
    "print(f\"  Window: 20, Std: 2.0\")\n",
    "print(f\"  Entry filter: Optional CUSUM filter on volatility\")\n",
    "print(f\"  Triple-barrier: pt_sl=[1, 2], vertical_barrier=50 bars\")\n",
    "\n",
    "print(f\"\\nMeta-Labeling Approach:\")\n",
    "print(f\"  1 (TAKE_TRADE): ML agrees with primary strategy → execute trade\")\n",
    "print(f\"  0 (SKIP_TRADE): ML disagrees with primary strategy → skip trade\")\n",
    "print(f\"  Purpose: Filter primary strategy signals to improve performance\")\n",
    "\n",
    "print(f\"\\n✓ Data preparation complete!\")\n",
    "print(f\"✓ Ready for Random Forest training with meta-labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18a1671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of prepared training data:\n",
      "\n",
      "Features (first 3 rows, first 10 columns):\n",
      "                     rel_spread  bb_bandwidth  bb_percentage   returns  \\\n",
      "time                                                                     \n",
      "2022-09-05 00:10:00    0.105830  1.150291e-15       0.592105  0.521572   \n",
      "2022-09-05 05:20:00    0.000894  4.834720e-02       0.709256  0.483286   \n",
      "2022-09-05 05:25:00    0.000897  6.297229e-02       0.704962  0.461391   \n",
      "\n",
      "                     returns_5  returns_10  returns_1_lag_1  returns_5_lag_1  \\\n",
      "time                                                                           \n",
      "2022-09-05 00:10:00   0.511677    0.503692         0.521572         0.589950   \n",
      "2022-09-05 05:20:00   0.465712    0.470195         0.483286         0.590766   \n",
      "2022-09-05 05:25:00   0.440238    0.449652         0.461391         0.573650   \n",
      "\n",
      "                     returns_10_lag_1  returns_1_lag_2  \n",
      "time                                                    \n",
      "2022-09-05 00:10:00          0.497610         0.521572  \n",
      "2022-09-05 05:20:00          0.507900         0.481930  \n",
      "2022-09-05 05:25:00          0.509108         0.483286  \n",
      "\n",
      "Labels (first 10):\n",
      "time\n",
      "2022-09-05 00:10:00    0\n",
      "2022-09-05 05:20:00    1\n",
      "2022-09-05 05:25:00    1\n",
      "2022-09-05 07:45:00    1\n",
      "2022-09-05 08:05:00    1\n",
      "2022-09-05 09:55:00    1\n",
      "2022-09-05 10:35:00    1\n",
      "2022-09-05 13:15:00    1\n",
      "2022-09-05 13:25:00    1\n",
      "2022-09-05 16:05:00    1\n",
      "Name: bin, dtype: int64\n",
      "\n",
      "Sample weights (first 10):\n"
     ]
    }
   ],
   "source": [
    "# Quick preview of prepared data\n",
    "print(\"Sample of prepared training data:\")\n",
    "print(\"\\nFeatures (first 3 rows, first 10 columns):\")\n",
    "print(X_train_scaled.iloc[:3, :10])\n",
    "print(\"\\nLabels (first 10):\")\n",
    "print(y_train.head(10))\n",
    "print(\"\\nSample weights (first 10):\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
