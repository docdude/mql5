{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cffc81d",
   "metadata": {},
   "source": [
    "# Training Data Preparation: Trend-Scanning\n",
    "\n",
    "This notebook prepares the final training dataset for the trend-scanning approach by:\n",
    "\n",
    "1. **Loading features** from `features_trend_scanning.csv`\n",
    "2. **Loading labels** from trend-scanning labels CSV\n",
    "3. **Merging** features with labels on timestamp\n",
    "4. **Extracting sample weights** from t-values (statistical significance)\n",
    "5. **Preprocessing features** with MinMax normalization\n",
    "6. **Time-based train/test split** (no shuffling to preserve temporal order)\n",
    "7. **Saving ready-to-use datasets** for model training\n",
    "\n",
    "**Key Insight from Article:**\n",
    "- Use **t-values as sample weights** to emphasize statistically stronger trends\n",
    "- Weighted models significantly outperform unweighted (Sharpe: 2.62 vs varies wildly)\n",
    "- This approach delivered +37% Sharpe improvement and +88% Sortino improvement in out-of-sample testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1698799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from strategies import MACrossoverStrategy\n",
    "from volatility import get_daily_vol\n",
    "from signal_processing import get_entries\n",
    "\n",
    "from load_data import load_bars\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcffacf",
   "metadata": {},
   "source": [
    "## 1. Load Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265472ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features from data/features_trend_scanning.csv...\n",
      "✓ Features loaded: (332916, 96)\n",
      "  Date range: 2022-09-02 00:05:00 to 2025-10-31 23:00:00\n",
      "  Columns: 96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ma_10</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_50</th>\n",
       "      <th>ma_100</th>\n",
       "      <th>ma_200</th>\n",
       "      <th>ma_10_20_cross</th>\n",
       "      <th>ma_20_50_cross</th>\n",
       "      <th>ma_50_200_cross</th>\n",
       "      <th>ma_spread_10_20</th>\n",
       "      <th>ma_spread_20_50</th>\n",
       "      <th>...</th>\n",
       "      <th>inside_bar</th>\n",
       "      <th>outside_bar</th>\n",
       "      <th>near_recent_high</th>\n",
       "      <th>near_recent_low</th>\n",
       "      <th>fractal_trend_strength</th>\n",
       "      <th>fractal_trend_direction</th>\n",
       "      <th>fractal_ma_ratio</th>\n",
       "      <th>fractal_trend_confirmation</th>\n",
       "      <th>distance_to_fractal_resistance</th>\n",
       "      <th>distance_to_fractal_support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ma_10  ma_20  ma_50  ma_100  ma_200  ma_10_20_cross  \\\n",
       "time                                                                       \n",
       "2022-09-02 00:05:00    0.0    0.0    0.0     0.0     0.0             0.0   \n",
       "2022-09-02 00:10:00    0.0    0.0    0.0     0.0     0.0            -1.0   \n",
       "2022-09-02 00:15:00    0.0    0.0    0.0     0.0     0.0            -1.0   \n",
       "\n",
       "                     ma_20_50_cross  ma_50_200_cross  ma_spread_10_20  \\\n",
       "time                                                                    \n",
       "2022-09-02 00:05:00             0.0              0.0              0.0   \n",
       "2022-09-02 00:10:00            -1.0             -1.0              0.0   \n",
       "2022-09-02 00:15:00            -1.0             -1.0              0.0   \n",
       "\n",
       "                     ma_spread_20_50  ...  inside_bar  outside_bar  \\\n",
       "time                                  ...                            \n",
       "2022-09-02 00:05:00              0.0  ...         0.0          0.0   \n",
       "2022-09-02 00:10:00              0.0  ...         0.0          0.0   \n",
       "2022-09-02 00:15:00              0.0  ...         0.0          0.0   \n",
       "\n",
       "                     near_recent_high  near_recent_low  \\\n",
       "time                                                     \n",
       "2022-09-02 00:05:00               0.0              0.0   \n",
       "2022-09-02 00:10:00               0.0              0.0   \n",
       "2022-09-02 00:15:00               0.0              0.0   \n",
       "\n",
       "                     fractal_trend_strength  fractal_trend_direction  \\\n",
       "time                                                                   \n",
       "2022-09-02 00:05:00                     0.0                      0.0   \n",
       "2022-09-02 00:10:00                     0.0                      0.0   \n",
       "2022-09-02 00:15:00                     0.0                      0.0   \n",
       "\n",
       "                     fractal_ma_ratio  fractal_trend_confirmation  \\\n",
       "time                                                                \n",
       "2022-09-02 00:05:00               0.0                         0.0   \n",
       "2022-09-02 00:10:00               0.0                         0.0   \n",
       "2022-09-02 00:15:00               0.0                         0.0   \n",
       "\n",
       "                     distance_to_fractal_resistance  \\\n",
       "time                                                  \n",
       "2022-09-02 00:05:00                             0.0   \n",
       "2022-09-02 00:10:00                             0.0   \n",
       "2022-09-02 00:15:00                             0.0   \n",
       "\n",
       "                     distance_to_fractal_support  \n",
       "time                                              \n",
       "2022-09-02 00:05:00                          0.0  \n",
       "2022-09-02 00:10:00                          0.0  \n",
       "2022-09-02 00:15:00                          0.0  \n",
       "\n",
       "[3 rows x 96 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load features\n",
    "features_file = 'data/features_trend_scanning.csv'\n",
    "print(f\"Loading features from {features_file}...\")\n",
    "features = pd.read_csv(features_file, index_col=0, parse_dates=True)\n",
    "\n",
    "print(f\"✓ Features loaded: {features.shape}\")\n",
    "print(f\"  Date range: {features.index[0]} to {features.index[-1]}\")\n",
    "print(f\"  Columns: {len(features.columns)}\")\n",
    "features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5739032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Labels loaded: (332817, 7)\n",
      "  Date range: 2022-09-02 00:05:00 to 2025-10-31 14:45:00\n",
      "  Columns: ['t1', 'window', 'slope', 't_value', 'rsquared', 'ret', 'bin']\n",
      "\n",
      "Label distribution:\n",
      "bin\n",
      "-1    114356\n",
      " 0     96788\n",
      " 1    121673\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>window</th>\n",
       "      <th>slope</th>\n",
       "      <th>t_value</th>\n",
       "      <th>rsquared</th>\n",
       "      <th>ret</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:05:00</th>\n",
       "      <td>2022-09-02 00:25:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:10:00</th>\n",
       "      <td>2022-09-02 00:30:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:15:00</th>\n",
       "      <td>2022-09-02 00:35:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      t1  window  slope  t_value  rsquared  \\\n",
       "2022-09-02 00:05:00  2022-09-02 00:25:00       5    0.0      0.0       0.0   \n",
       "2022-09-02 00:10:00  2022-09-02 00:30:00       5    0.0      0.0       0.0   \n",
       "2022-09-02 00:15:00  2022-09-02 00:35:00       5    0.0      0.0       0.0   \n",
       "\n",
       "                          ret  bin  \n",
       "2022-09-02 00:05:00  0.000372    0  \n",
       "2022-09-02 00:10:00  0.000307    0  \n",
       "2022-09-02 00:15:00  0.000312    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and load the most recent trend labels file\n",
    "data_dir = Path('data')\n",
    "label_files = list(data_dir.glob('EURUSD_trend_labels.csv'))\n",
    "\n",
    "if not label_files:\n",
    "    raise FileNotFoundError(\"No trend labels file found! Run trend_scanning.ipynb first.\")\n",
    "\n",
    "labels = pd.read_csv(label_files[0], index_col=0, parse_dates=True)\n",
    "\n",
    "print(f\"✓ Labels loaded: {labels.shape}\")\n",
    "print(f\"  Date range: {labels.index[0]} to {labels.index[-1]}\")\n",
    "print(f\"  Columns: {list(labels.columns)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(labels['bin'].value_counts().sort_index())\n",
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53635c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading time bars from: EURUSD_time_bars_20251102_145959.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EURUSD M5 time bars...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loaded 332,916 time bars\n",
      "INFO:   Start: 2022-09-02 00:05:00\n",
      "INFO:   End: 2025-10-31 23:00:00\n",
      "INFO:   Columns: ['open', 'high', 'low', 'close', 'tick_volume', 'bid_open', 'bid_high', 'bid_low', 'bid_close', 'ask_open', 'ask_high', 'ask_low', 'ask_close']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bars loaded: 332,916 observations\n",
      "  Date range: 2022-09-02 00:05:00 to 2025-10-31 23:00:00\n",
      "  Columns: ['open', 'high', 'low', 'close', 'tick_volume', 'bid_open', 'bid_high', 'bid_low', 'bid_close', 'ask_open', 'ask_high', 'ask_low', 'ask_close']\n",
      "\n",
      "✓ Volatility calculated (20-day EWM)\n",
      "  Mean volatility: 0.000581\n",
      "  Median volatility: 0.000437\n",
      "\n",
      "✓ CUSUM filter threshold set to mean volatility: 0.000581\n"
     ]
    }
   ],
   "source": [
    "# Load EURUSD M5 time bars for trend-scanning experiment\n",
    "# Following the article: EURUSD M5 from 2018-01-01 to 2021-12-31 (train/validation)\n",
    "print(\"Loading EURUSD M5 time bars...\")\n",
    "df = load_bars('EURUSD', 'time')\n",
    "\n",
    "print(f\"✓ Bars loaded: {len(df):,} observations\")\n",
    "print(f\"  Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "print(f\"  Columns: {list(df.columns)}\")\n",
    "\n",
    "# Calculate 20-day EWM volatility (as per article)\n",
    "target = get_daily_vol(df['close'], lookback=20)\n",
    "print(f\"\\n✓ Volatility calculated (20-day EWM)\")\n",
    "print(f\"  Mean volatility: {target.mean():.6f}\")\n",
    "print(f\"  Median volatility: {target.median():.6f}\")\n",
    "\n",
    "# Set CUSUM filter threshold (as per article methodology)\n",
    "cusum_filter_threshold = target.mean()\n",
    "print(f\"\\n✓ CUSUM filter threshold set to mean volatility: {cusum_filter_threshold:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9ef89a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 30,899 CUSUM-filtered events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-02 17:13:24.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msignal_processing\u001b[0m:\u001b[36mget_entries\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mGenerated 830 trade events generated by crossover + CUSUM filter.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 830 entry events\n",
      "\n",
      "Side distribution:\n",
      "side\n",
      "-1    180850\n",
      " 1    152017\n",
      " 0        49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few events:\n",
      "DatetimeIndex(['2022-09-02 04:10:00', '2022-09-05 00:10:00',\n",
      "               '2022-09-05 05:25:00', '2022-09-05 10:40:00',\n",
      "               '2022-09-06 01:15:00'],\n",
      "              dtype='datetime64[ns]', name='time', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Create a strategy instance\n",
    "strategy = MACrossoverStrategy(fast_window=20, slow_window=50)\n",
    "\n",
    "# Generate entry signals\n",
    "sides, t_events = get_entries(\n",
    "    strategy=strategy,\n",
    "    data=df,\n",
    "    filter_events=True,\n",
    "    filter_threshold=cusum_filter_threshold,\n",
    "    on_crossover=True,\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(t_events):,} entry events\")\n",
    "print(f\"\\nSide distribution:\")\n",
    "print(sides.value_counts())\n",
    "print(f\"\\nFirst few events:\")\n",
    "print(t_events[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "901583ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA crossover events: 830\n",
      "Trend-scanning labels: 332,817\n",
      "Common timestamps: 829\n",
      "\n",
      "✓ Meta-labels created: 829\n",
      "\n",
      "Meta-label distribution:\n",
      "meta_label\n",
      "0    420\n",
      "1    409\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Breakdown by strategy side:\n",
      "  SHORT: 445 events, 46.5% agree with trend-scanning\n",
      "  LONG: 384 events, 52.6% agree with trend-scanning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>window</th>\n",
       "      <th>slope</th>\n",
       "      <th>t_value</th>\n",
       "      <th>rsquared</th>\n",
       "      <th>ret</th>\n",
       "      <th>bin</th>\n",
       "      <th>side</th>\n",
       "      <th>meta_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-02 04:10:00</th>\n",
       "      <td>2022-09-02 11:55:00</td>\n",
       "      <td>94</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>16.660364</td>\n",
       "      <td>0.751234</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 00:10:00</th>\n",
       "      <td>2022-09-05 08:20:00</td>\n",
       "      <td>99</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-10.172517</td>\n",
       "      <td>0.516391</td>\n",
       "      <td>-0.004134</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 05:25:00</th>\n",
       "      <td>2022-09-05 06:25:00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>8.646405</td>\n",
       "      <td>0.871797</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05 10:40:00</th>\n",
       "      <td>2022-09-05 11:10:00</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.000277</td>\n",
       "      <td>-6.244016</td>\n",
       "      <td>0.886383</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06 01:15:00</th>\n",
       "      <td>2022-09-06 04:45:00</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>16.366613</td>\n",
       "      <td>0.867309</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 02:05:00</th>\n",
       "      <td>2022-09-07 03:15:00</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>9.322426</td>\n",
       "      <td>0.869982</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 08:10:00</th>\n",
       "      <td>2022-09-07 11:55:00</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7.888990</td>\n",
       "      <td>0.585894</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 17:10:00</th>\n",
       "      <td>2022-09-08 01:20:00</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>23.884285</td>\n",
       "      <td>0.854737</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08 02:30:00</th>\n",
       "      <td>2022-09-08 04:05:00</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-7.304482</td>\n",
       "      <td>0.747843</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09 10:30:00</th>\n",
       "      <td>2022-09-09 18:40:00</td>\n",
       "      <td>99</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-20.979967</td>\n",
       "      <td>0.819501</td>\n",
       "      <td>-0.006965</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      t1  window     slope    t_value  \\\n",
       "2022-09-02 04:10:00  2022-09-02 11:55:00      94  0.000036  16.660364   \n",
       "2022-09-05 00:10:00  2022-09-05 08:20:00      99 -0.000023 -10.172517   \n",
       "2022-09-05 05:25:00  2022-09-05 06:25:00      13  0.000116   8.646405   \n",
       "2022-09-05 10:40:00  2022-09-05 11:10:00       7 -0.000277  -6.244016   \n",
       "2022-09-06 01:15:00  2022-09-06 04:45:00      43  0.000076  16.366613   \n",
       "2022-09-07 02:05:00  2022-09-07 03:15:00      15  0.000074   9.322426   \n",
       "2022-09-07 08:10:00  2022-09-07 11:55:00      46  0.000066   7.888990   \n",
       "2022-09-07 17:10:00  2022-09-08 01:20:00      99  0.000093  23.884285   \n",
       "2022-09-08 02:30:00  2022-09-08 04:05:00      20 -0.000068  -7.304482   \n",
       "2022-09-09 10:30:00  2022-09-09 18:40:00      99 -0.000077 -20.979967   \n",
       "\n",
       "                     rsquared       ret  bin  side  meta_label  \n",
       "2022-09-02 04:10:00  0.751234  0.002470    1     1           1  \n",
       "2022-09-05 00:10:00  0.516391 -0.004134   -1    -1           1  \n",
       "2022-09-05 05:25:00  0.871797  0.001404    1    -1           0  \n",
       "2022-09-05 10:40:00  0.886383 -0.001391   -1     1           0  \n",
       "2022-09-06 01:15:00  0.867309  0.002278    1     1           1  \n",
       "2022-09-07 02:05:00  0.869982  0.000743    1    -1           0  \n",
       "2022-09-07 08:10:00  0.585894  0.001515    1     1           1  \n",
       "2022-09-07 17:10:00  0.854737  0.009876    1     1           1  \n",
       "2022-09-08 02:30:00  0.747843 -0.000770   -1    -1           1  \n",
       "2022-09-09 10:30:00  0.819501 -0.006965   -1     1           0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create meta-labels by combining MA side with trend-scanning bin\n",
    "# Find intersection of t_events and available labels\n",
    "common_timestamps = t_events.intersection(labels.index)\n",
    "\n",
    "print(f\"MA crossover events: {len(t_events):,}\")\n",
    "print(f\"Trend-scanning labels: {len(labels):,}\")\n",
    "print(f\"Common timestamps: {len(common_timestamps):,}\")\n",
    "\n",
    "if len(common_timestamps) == 0:\n",
    "    raise ValueError(\"No common timestamps between t_events and labels! Check data alignment.\")\n",
    "\n",
    "# Filter to only common timestamps\n",
    "meta_labels = labels.loc[common_timestamps].copy()\n",
    "\n",
    "# Create meta-labels: 1 if MA side agrees with trend-scanning bin, 0 otherwise\n",
    "# MA side: 1 (long) or -1 (short)\n",
    "# Trend bin: 1 (up), -1 (down), 0 (neutral)\n",
    "# Agreement: side * bin > 0 means they agree in direction\n",
    "meta_labels['side'] = sides.loc[common_timestamps].values\n",
    "meta_labels['meta_label'] = ((meta_labels['side'] * meta_labels['bin']) > 0).astype(int)\n",
    "\n",
    "print(f\"\\n✓ Meta-labels created: {len(meta_labels):,}\")\n",
    "print(f\"\\nMeta-label distribution:\")\n",
    "print(meta_labels['meta_label'].value_counts().sort_index())\n",
    "print(f\"\\nBreakdown by strategy side:\")\n",
    "for side_val in [-1, 1]:\n",
    "    side_name = \"SHORT\" if side_val == -1 else \"LONG\"\n",
    "    side_data = meta_labels[meta_labels['side'] == side_val]\n",
    "    if len(side_data) > 0:\n",
    "        agree_pct = (side_data['meta_label'] == 1).sum() / len(side_data) * 100\n",
    "        print(f\"  {side_name}: {len(side_data):,} events, {agree_pct:.1f}% agree with trend-scanning\")\n",
    "\n",
    "meta_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100bcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging features with labels...\n",
      "  Features: 332,916 rows\n",
      "  Labels: 332,817 rows\n",
      "\n",
      "✓ Merged dataset: (332817, 103)\n",
      "  Date range: 2022-09-02 00:05:00 to 2025-10-31 14:45:00\n",
      "  Lost 99 observations due to missing labels\n",
      "\n",
      "Missing values check:\n",
      "  Features: 0\n",
      "  Labels (bin): 0\n",
      "  Weights (t_value): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ma_10</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_50</th>\n",
       "      <th>ma_100</th>\n",
       "      <th>ma_200</th>\n",
       "      <th>ma_10_20_cross</th>\n",
       "      <th>ma_20_50_cross</th>\n",
       "      <th>ma_50_200_cross</th>\n",
       "      <th>ma_spread_10_20</th>\n",
       "      <th>ma_spread_20_50</th>\n",
       "      <th>...</th>\n",
       "      <th>fractal_trend_confirmation</th>\n",
       "      <th>distance_to_fractal_resistance</th>\n",
       "      <th>distance_to_fractal_support</th>\n",
       "      <th>t1</th>\n",
       "      <th>window</th>\n",
       "      <th>slope</th>\n",
       "      <th>t_value</th>\n",
       "      <th>rsquared</th>\n",
       "      <th>ret</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-09-02 00:25:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-09-02 00:30:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-09-02 00:35:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ma_10  ma_20  ma_50  ma_100  ma_200  ma_10_20_cross  \\\n",
       "2022-09-02 00:05:00    0.0    0.0    0.0     0.0     0.0             0.0   \n",
       "2022-09-02 00:10:00    0.0    0.0    0.0     0.0     0.0            -1.0   \n",
       "2022-09-02 00:15:00    0.0    0.0    0.0     0.0     0.0            -1.0   \n",
       "\n",
       "                     ma_20_50_cross  ma_50_200_cross  ma_spread_10_20  \\\n",
       "2022-09-02 00:05:00             0.0              0.0              0.0   \n",
       "2022-09-02 00:10:00            -1.0             -1.0              0.0   \n",
       "2022-09-02 00:15:00            -1.0             -1.0              0.0   \n",
       "\n",
       "                     ma_spread_20_50  ...  fractal_trend_confirmation  \\\n",
       "2022-09-02 00:05:00              0.0  ...                         0.0   \n",
       "2022-09-02 00:10:00              0.0  ...                         0.0   \n",
       "2022-09-02 00:15:00              0.0  ...                         0.0   \n",
       "\n",
       "                     distance_to_fractal_resistance  \\\n",
       "2022-09-02 00:05:00                             0.0   \n",
       "2022-09-02 00:10:00                             0.0   \n",
       "2022-09-02 00:15:00                             0.0   \n",
       "\n",
       "                     distance_to_fractal_support                   t1  window  \\\n",
       "2022-09-02 00:05:00                          0.0  2022-09-02 00:25:00       5   \n",
       "2022-09-02 00:10:00                          0.0  2022-09-02 00:30:00       5   \n",
       "2022-09-02 00:15:00                          0.0  2022-09-02 00:35:00       5   \n",
       "\n",
       "                     slope  t_value  rsquared       ret  bin  \n",
       "2022-09-02 00:05:00    0.0      0.0       0.0  0.000372    0  \n",
       "2022-09-02 00:10:00    0.0      0.0       0.0  0.000307    0  \n",
       "2022-09-02 00:15:00    0.0      0.0       0.0  0.000312    0  \n",
       "\n",
       "[3 rows x 103 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge features with meta-labels (on timestamp)\n",
    "print(\"Merging features with meta-labels...\")\n",
    "print(f\"  Features: {len(features):,} rows\")\n",
    "print(f\"  Meta-labels: {len(meta_labels):,} rows\")\n",
    "\n",
    "# Inner join on index (timestamp) - only keep rows with both features and meta-labels\n",
    "data = features.join(meta_labels, how='inner', rsuffix='_meta')\n",
    "\n",
    "print(f\"\\n✓ Merged dataset: {data.shape}\")\n",
    "print(f\"  Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "print(f\"  Lost {len(features) - len(data):,} observations due to missing meta-labels\")\n",
    "\n",
    "# Verify no missing values in critical columns\n",
    "print(f\"\\nMissing values check:\")\n",
    "print(f\"  Features: {data[features.columns].isnull().sum().sum()}\")\n",
    "print(f\"  Meta-label (meta_label): {data['meta_label'].isnull().sum()}\")\n",
    "print(f\"  Weights (t_value): {data['t_value'].isnull().sum()}\")\n",
    "print(f\"  Side: {data['side'].isnull().sum()}\")\n",
    "\n",
    "print(f\"\\nColumns in merged dataset:\")\n",
    "print(f\"  Total: {len(data.columns)}\")\n",
    "print(f\"  Features: {len(features.columns)}\")\n",
    "print(f\"  Meta-label columns: {[col for col in data.columns if col not in features.columns]}\")\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a741f",
   "metadata": {},
   "source": [
    "## 3. Prepare Features, Labels, and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af18fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET COMPOSITION\n",
      "================================================================================\n",
      "Features (X): (332817, 96)\n",
      "Labels (y): (332817,)\n",
      "Sample weights: (332817,)\n",
      "Label metadata: (332817, 6)\n",
      "\n",
      "Label distribution:\n",
      "  DOWN     (-1): 114,356 (34.36%)\n",
      "  NEUTRAL  ( 0): 96,788 (29.08%)\n",
      "  UP       ( 1): 121,673 (36.56%)\n",
      "\n",
      "Sample weights statistics:\n",
      "  Mean: 10.4319\n",
      "  Median: 10.4436\n",
      "  Min: 0.0000\n",
      "  Max: 205.0355\n",
      "  Std: 8.8540\n"
     ]
    }
   ],
   "source": [
    "# Separate features, labels, and sample weights\n",
    "feature_cols = features.columns.tolist()\n",
    "X = data[feature_cols].copy()\n",
    "y = data['meta_label'].copy()  # Use meta_label (0 or 1) instead of bin (-1, 0, 1)\n",
    "sample_weights = data['t_value'].abs().copy()  # Use absolute t-value as weight\n",
    "label_metadata = data[['t1', 'window', 'slope', 't_value', 'rsquared', 'ret', 'bin', 'side']].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"META-LABELING DATASET COMPOSITION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Meta-labels (y): {y.shape}\")\n",
    "print(f\"Sample weights: {sample_weights.shape}\")\n",
    "print(f\"Label metadata: {label_metadata.shape}\")\n",
    "\n",
    "print(f\"\\nMeta-label distribution:\")\n",
    "label_counts = y.value_counts().sort_index()\n",
    "for label, count in label_counts.items():\n",
    "    pct = count / len(y) * 100\n",
    "    label_name = {0: 'SKIP (disagree)', 1: 'TAKE (agree)'}.get(label, 'UNKNOWN')\n",
    "    print(f\"  {label_name:20s} ({label:2d}): {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nOriginal trend-scanning bin distribution:\")\n",
    "bin_counts = data['bin'].value_counts().sort_index()\n",
    "for bin_val, count in bin_counts.items():\n",
    "    pct = count / len(data) * 100\n",
    "    bin_name = {-1: 'DOWN', 0: 'NEUTRAL', 1: 'UP'}.get(bin_val, 'UNKNOWN')\n",
    "    print(f\"  {bin_name:8s} ({bin_val:2d}): {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nStrategy side distribution:\")\n",
    "side_counts = data['side'].value_counts().sort_index()\n",
    "for side_val, count in side_counts.items():\n",
    "    pct = count / len(data) * 100\n",
    "    side_name = {-1: 'SHORT', 1: 'LONG'}.get(side_val, 'UNKNOWN')\n",
    "    print(f\"  {side_name:8s} ({side_val:2d}): {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nSample weights statistics:\")\n",
    "print(f\"  Mean: {sample_weights.mean():.4f}\")\n",
    "print(f\"  Median: {sample_weights.median():.4f}\")\n",
    "print(f\"  Min: {sample_weights.min():.4f}\")\n",
    "print(f\"  Max: {sample_weights.max():.4f}\")\n",
    "print(f\"  Std: {sample_weights.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588d8bc",
   "metadata": {},
   "source": [
    "## 4. Feature Normalization (MinMax Scaling)\n",
    "\n",
    "**Important:** We normalize features to [0, 1] range to:\n",
    "- Ensure all features contribute equally to the model\n",
    "- Improve convergence for tree-based models\n",
    "- Make feature importance more interpretable\n",
    "\n",
    "**Note:** We fit the scaler on training data and transform both train and test to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d2cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature statistics check:\n",
      "  Features with inf: 0\n",
      "  Features with NaN: 0\n",
      "\n",
      "⚠ WARNING - Constant columns detected (1): ['sunday_open_vol']\n",
      "  These will be removed before normalization\n",
      "\n",
      "Final feature count: 95\n"
     ]
    }
   ],
   "source": [
    "# We'll normalize after train/test split to prevent leakage\n",
    "# For now, just check for any extreme values or issues\n",
    "\n",
    "print(\"Feature statistics check:\")\n",
    "print(f\"  Features with inf: {np.isinf(X).sum().sum()}\")\n",
    "print(f\"  Features with NaN: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# Check for constant columns (would cause issues in normalization)\n",
    "constant_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(f\"\\n⚠ WARNING - Constant columns detected ({len(constant_cols)}): {constant_cols}\")\n",
    "    print(f\"  These will be removed before normalization\")\n",
    "    X = X.drop(columns=constant_cols)\n",
    "    feature_cols = X.columns.tolist()\n",
    "else:\n",
    "    print(f\"  ✓ No constant columns detected\")\n",
    "\n",
    "print(f\"\\nFinal feature count: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c78d8",
   "metadata": {},
   "source": [
    "## 5. Time-Based Train/Test Split\n",
    "\n",
    "**Critical for time-series:**\n",
    "- No shuffling (preserves temporal order)\n",
    "- Train on earlier data, test on later data\n",
    "- Simulates real-world deployment scenario\n",
    "- Standard split: 70% train, 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b212a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAIN/TEST SPLIT (Time-Based, No Shuffling)\n",
      "================================================================================\n",
      "Split ratio: 70% train / 30% test\n",
      "Split index: 232,971\n",
      "\n",
      "Train set:\n",
      "  Shape: (232971, 95)\n",
      "  Date range: 2022-09-02 00:05:00 to 2024-11-18 22:15:00\n",
      "  Label distribution:\n",
      "    DOWN     (-1): 80,002 (34.34%)\n",
      "    NEUTRAL  ( 0): 67,858 (29.13%)\n",
      "    UP       ( 1): 85,111 (36.53%)\n",
      "\n",
      "Test set:\n",
      "  Shape: (99846, 95)\n",
      "  Date range: 2024-11-18 22:20:00 to 2025-10-31 14:45:00\n",
      "  Label distribution:\n",
      "    DOWN     (-1): 34,354 (34.41%)\n",
      "    NEUTRAL  ( 0): 28,930 (28.97%)\n",
      "    UP       ( 1): 36,562 (36.62%)\n"
     ]
    }
   ],
   "source": [
    "# Time-based split (70/30)\n",
    "split_ratio = 0.70\n",
    "split_idx = int(len(data) * split_ratio)\n",
    "\n",
    "# Split data\n",
    "X_train = X.iloc[:split_idx].copy()\n",
    "X_test = X.iloc[split_idx:].copy()\n",
    "y_train = y.iloc[:split_idx].copy()\n",
    "y_test = y.iloc[split_idx:].copy()\n",
    "weights_train = sample_weights.iloc[:split_idx].copy()\n",
    "weights_test = sample_weights.iloc[split_idx:].copy()\n",
    "metadata_train = label_metadata.iloc[:split_idx].copy()\n",
    "metadata_test = label_metadata.iloc[split_idx:].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAIN/TEST SPLIT (Time-Based, No Shuffling)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Split ratio: {split_ratio:.0%} train / {1-split_ratio:.0%} test\")\n",
    "print(f\"Split index: {split_idx:,}\")\n",
    "print(f\"\\nTrain set:\")\n",
    "print(f\"  Shape: {X_train.shape}\")\n",
    "print(f\"  Date range: {X_train.index[0]} to {X_train.index[-1]}\")\n",
    "print(f\"  Label distribution:\")\n",
    "for label, count in y_train.value_counts().sort_index().items():\n",
    "    pct = count / len(y_train) * 100\n",
    "    label_name = {-1: 'DOWN', 0: 'NEUTRAL', 1: 'UP'}.get(label, 'UNKNOWN')\n",
    "    print(f\"    {label_name:8s} ({label:2d}): {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Shape: {X_test.shape}\")\n",
    "print(f\"  Date range: {X_test.index[0]} to {X_test.index[-1]}\")\n",
    "print(f\"  Label distribution:\")\n",
    "for label, count in y_test.value_counts().sort_index().items():\n",
    "    pct = count / len(y_test) * 100\n",
    "    label_name = {-1: 'DOWN', 0: 'NEUTRAL', 1: 'UP'}.get(label, 'UNKNOWN')\n",
    "    print(f\"    {label_name:8s} ({label:2d}): {count:6,} ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80916357",
   "metadata": {},
   "source": [
    "## 6. Normalize Features with MinMax Scaler\n",
    "\n",
    "**Fit on train, transform both train and test** to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c49942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MinMaxScaler on training data...\n",
      "Transforming features to [0, 1] range...\n",
      "✓ Normalization complete\n",
      "\n",
      "Scaled feature statistics (train):\n",
      "  Min: 0.000000\n",
      "  Max: 1.000000\n",
      "  Mean: 0.395174\n",
      "  Std: 0.199742\n",
      "\n",
      "Scaled feature statistics (test):\n",
      "  Min: -0.355090\n",
      "  Max: 1.365021\n",
      "  Mean: 0.404283\n",
      "  Std: 0.204104\n",
      "\n",
      "Data quality check (post-scaling):\n",
      "  Train - NaN: 0, Inf: 0\n",
      "  Test - NaN: 0, Inf: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit scaler on training data only\n",
    "print(\"Fitting MinMaxScaler on training data...\")\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both train and test\n",
    "print(\"Transforming features to [0, 1] range...\")\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    index=X_test.index,\n",
    "    columns=X_test.columns\n",
    ")\n",
    "\n",
    "print(f\"✓ Normalization complete\")\n",
    "print(f\"\\nScaled feature statistics (train):\")\n",
    "print(f\"  Min: {X_train_scaled.min().min():.6f}\")\n",
    "print(f\"  Max: {X_train_scaled.max().max():.6f}\")\n",
    "print(f\"  Mean: {X_train_scaled.mean().mean():.6f}\")\n",
    "print(f\"  Std: {X_train_scaled.std().mean():.6f}\")\n",
    "\n",
    "print(f\"\\nScaled feature statistics (test):\")\n",
    "print(f\"  Min: {X_test_scaled.min().min():.6f}\")\n",
    "print(f\"  Max: {X_test_scaled.max().max():.6f}\")\n",
    "print(f\"  Mean: {X_test_scaled.mean().mean():.6f}\")\n",
    "print(f\"  Std: {X_test_scaled.std().mean():.6f}\")\n",
    "\n",
    "# Verify no NaN or inf after scaling\n",
    "print(f\"\\nData quality check (post-scaling):\")\n",
    "print(f\"  Train - NaN: {X_train_scaled.isnull().sum().sum()}, Inf: {np.isinf(X_train_scaled).sum().sum()}\")\n",
    "print(f\"  Test - NaN: {X_test_scaled.isnull().sum().sum()}, Inf: {np.isinf(X_test_scaled).sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c1554",
   "metadata": {},
   "source": [
    "## 7. Save Processed Datasets\n",
    "\n",
    "Save **ready-to-use** datasets for model training:\n",
    "- Features (normalized)\n",
    "- Labels\n",
    "- Sample weights (t-values)\n",
    "- Label metadata (for analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9374c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING PROCESSED DATASETS\n",
      "================================================================================\n",
      "Train set saved:\n",
      "  Features: X_train_trend_scanning_20251102_171209.csv\n",
      "  Labels: y_train_trend_scanning_20251102_171209.csv\n",
      "  Weights: weights_train_trend_scanning_20251102_171209.csv\n",
      "  Metadata: metadata_train_trend_scanning_20251102_171209.csv\n",
      "\n",
      "Test set saved:\n",
      "  Features: X_test_trend_scanning_20251102_171209.csv\n",
      "  Labels: y_test_trend_scanning_20251102_171209.csv\n",
      "  Weights: weights_test_trend_scanning_20251102_171209.csv\n",
      "  Metadata: metadata_test_trend_scanning_20251102_171209.csv\n",
      "\n",
      "Feature names: feature_names_trend_scanning_20251102_171209.txt\n",
      "\n",
      "================================================================================\n",
      "✓ ALL DATASETS SAVED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "Datasets ready for model training in: data\\training\n",
      "\n",
      "Next step: Create models.ipynb to train Random Forest with:\n",
      "  - Weighted samples (t-values)\n",
      "  - PurgedKFold cross-validation\n",
      "  - BaggingClassifier for ensemble\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('data/training')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING PROCESSED DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save train set\n",
    "train_features_file = output_dir / f'X_train_trend_scanning_{timestamp}.csv'\n",
    "train_labels_file = output_dir / f'y_train_trend_scanning_{timestamp}.csv'\n",
    "train_weights_file = output_dir / f'weights_train_trend_scanning_{timestamp}.csv'\n",
    "train_metadata_file = output_dir / f'metadata_train_trend_scanning_{timestamp}.csv'\n",
    "\n",
    "X_train_scaled.to_csv(train_features_file)\n",
    "y_train.to_csv(train_labels_file, header=True)\n",
    "weights_train.to_csv(train_weights_file, header=True)\n",
    "metadata_train.to_csv(train_metadata_file)\n",
    "\n",
    "print(f\"Train set saved:\")\n",
    "print(f\"  Features: {train_features_file.name}\")\n",
    "print(f\"  Labels: {train_labels_file.name}\")\n",
    "print(f\"  Weights: {train_weights_file.name}\")\n",
    "print(f\"  Metadata: {train_metadata_file.name}\")\n",
    "\n",
    "# Save test set\n",
    "test_features_file = output_dir / f'X_test_trend_scanning_{timestamp}.csv'\n",
    "test_labels_file = output_dir / f'y_test_trend_scanning_{timestamp}.csv'\n",
    "test_weights_file = output_dir / f'weights_test_trend_scanning_{timestamp}.csv'\n",
    "test_metadata_file = output_dir / f'metadata_test_trend_scanning_{timestamp}.csv'\n",
    "\n",
    "X_test_scaled.to_csv(test_features_file)\n",
    "y_test.to_csv(test_labels_file, header=True)\n",
    "weights_test.to_csv(test_weights_file, header=True)\n",
    "metadata_test.to_csv(test_metadata_file)\n",
    "\n",
    "print(f\"\\nTest set saved:\")\n",
    "print(f\"  Features: {test_features_file.name}\")\n",
    "print(f\"  Labels: {test_labels_file.name}\")\n",
    "print(f\"  Weights: {test_weights_file.name}\")\n",
    "print(f\"  Metadata: {test_metadata_file.name}\")\n",
    "\n",
    "# Save feature names for reference\n",
    "feature_names_file = output_dir / f'feature_names_trend_scanning_{timestamp}.txt'\n",
    "with open(feature_names_file, 'w') as f:\n",
    "    f.write(\"Trend-Scanning Feature Names\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    for i, col in enumerate(X_train_scaled.columns, 1):\n",
    "        f.write(f\"{i}. {col}\\n\")\n",
    "\n",
    "print(f\"\\nFeature names: {feature_names_file.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ ALL DATASETS SAVED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDatasets ready for model training in: {output_dir}\")\n",
    "print(f\"\\nNext step: Create models.ipynb to train Random Forest with:\")\n",
    "print(f\"  - Weighted samples (t-values)\")\n",
    "print(f\"  - PurgedKFold cross-validation\")\n",
    "print(f\"  - BaggingClassifier for ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f7999",
   "metadata": {},
   "source": [
    "## 8. Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc80621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Train Set:\n",
      "  Observations: 232,971\n",
      "  Features: 95\n",
      "  Date range: 2022-09-02 00:05:00 to 2024-11-18 22:15:00\n",
      "  Label distribution:\n",
      "    DOWN: 80,002 (34.34%)\n",
      "    NEUTRAL: 67,858 (29.13%)\n",
      "    UP: 85,111 (36.53%)\n",
      "  Sample weights: mean=10.4378, std=8.8548\n",
      "\n",
      "Test Set:\n",
      "  Observations: 99,846\n",
      "  Features: 95\n",
      "  Date range: 2024-11-18 22:20:00 to 2025-10-31 14:45:00\n",
      "  Label distribution:\n",
      "    DOWN: 34,354 (34.41%)\n",
      "    NEUTRAL: 28,930 (28.97%)\n",
      "    UP: 36,562 (36.62%)\n",
      "  Sample weights: mean=10.4182, std=8.8522\n",
      "\n",
      "Feature Normalization:\n",
      "  Method: MinMaxScaler\n",
      "  Range: [0, 1]\n",
      "  Fitted on: Train set only\n",
      "  Applied to: Both train and test\n",
      "\n",
      "Sample Weighting:\n",
      "  Method: Absolute t-values from trend-scanning\n",
      "  Purpose: Emphasize statistically significant trends\n",
      "  Range: [0.0000, 205.0355]\n",
      "\n",
      "✓ Data preparation complete!\n",
      "✓ Ready for Random Forest training with weighted samples\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  Observations: {len(X_train_scaled):,}\")\n",
    "print(f\"  Features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"  Date range: {X_train_scaled.index[0]} to {X_train_scaled.index[-1]}\")\n",
    "print(f\"  Label distribution:\")\n",
    "for label, count in y_train.value_counts().sort_index().items():\n",
    "    pct = count / len(y_train) * 100\n",
    "    label_name = {-1: 'DOWN', 0: 'NEUTRAL', 1: 'UP'}.get(label, 'UNKNOWN')\n",
    "    print(f\"    {label_name}: {count:,} ({pct:.2f}%)\")\n",
    "print(f\"  Sample weights: mean={weights_train.mean():.4f}, std={weights_train.std():.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  Observations: {len(X_test_scaled):,}\")\n",
    "print(f\"  Features: {X_test_scaled.shape[1]}\")\n",
    "print(f\"  Date range: {X_test_scaled.index[0]} to {X_test_scaled.index[-1]}\")\n",
    "print(f\"  Label distribution:\")\n",
    "for label, count in y_test.value_counts().sort_index().items():\n",
    "    pct = count / len(y_test) * 100\n",
    "    label_name = {-1: 'DOWN', 0: 'NEUTRAL', 1: 'UP'}.get(label, 'UNKNOWN')\n",
    "    print(f\"    {label_name}: {count:,} ({pct:.2f}%)\")\n",
    "print(f\"  Sample weights: mean={weights_test.mean():.4f}, std={weights_test.std():.4f}\")\n",
    "\n",
    "print(f\"\\nFeature Normalization:\")\n",
    "print(f\"  Method: MinMaxScaler\")\n",
    "print(f\"  Range: [0, 1]\")\n",
    "print(f\"  Fitted on: Train set only\")\n",
    "print(f\"  Applied to: Both train and test\")\n",
    "\n",
    "print(f\"\\nSample Weighting:\")\n",
    "print(f\"  Method: Absolute t-values from trend-scanning\")\n",
    "print(f\"  Purpose: Emphasize statistically significant trends\")\n",
    "print(f\"  Range: [{sample_weights.min():.4f}, {sample_weights.max():.4f}]\")\n",
    "\n",
    "print(f\"\\n✓ Data preparation complete!\")\n",
    "print(f\"✓ Ready for Random Forest training with weighted samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a578437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of prepared training data:\n",
      "\n",
      "Features (first 3 rows, first 10 columns):\n",
      "                     ma_10  ma_20  ma_50  ma_100  ma_200  ma_10_20_cross  \\\n",
      "2022-09-02 00:05:00    0.0    0.0    0.0     0.0     0.0             0.5   \n",
      "2022-09-02 00:10:00    0.0    0.0    0.0     0.0     0.0             0.0   \n",
      "2022-09-02 00:15:00    0.0    0.0    0.0     0.0     0.0             0.0   \n",
      "\n",
      "                     ma_20_50_cross  ma_50_200_cross  ma_spread_10_20  \\\n",
      "2022-09-02 00:05:00             0.5              0.5         0.023328   \n",
      "2022-09-02 00:10:00             0.0              0.0         0.023328   \n",
      "2022-09-02 00:15:00             0.0              0.0         0.023328   \n",
      "\n",
      "                     ma_spread_20_50  \n",
      "2022-09-02 00:05:00         0.909814  \n",
      "2022-09-02 00:10:00         0.909814  \n",
      "2022-09-02 00:15:00         0.909814  \n",
      "\n",
      "Labels (first 10):\n",
      "2022-09-02 00:05:00    0\n",
      "2022-09-02 00:10:00    0\n",
      "2022-09-02 00:15:00    0\n",
      "2022-09-02 00:20:00    1\n",
      "2022-09-02 00:25:00    1\n",
      "2022-09-02 00:30:00    1\n",
      "2022-09-02 00:35:00    1\n",
      "2022-09-02 00:40:00    1\n",
      "2022-09-02 00:45:00    1\n",
      "2022-09-02 00:50:00    1\n",
      "Name: bin, dtype: int64\n",
      "\n",
      "Sample weights (first 10):\n",
      "2022-09-02 00:05:00     0.000000\n",
      "2022-09-02 00:10:00     0.000000\n",
      "2022-09-02 00:15:00     0.000000\n",
      "2022-09-02 00:20:00    25.902941\n",
      "2022-09-02 00:25:00    26.217233\n",
      "2022-09-02 00:30:00    26.348808\n",
      "2022-09-02 00:35:00    26.237680\n",
      "2022-09-02 00:40:00    26.266049\n",
      "2022-09-02 00:45:00    26.471036\n",
      "2022-09-02 00:50:00    26.600549\n",
      "Name: t_value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Quick preview of prepared data\n",
    "print(\"Sample of prepared training data:\")\n",
    "print(\"\\nFeatures (first 3 rows, first 10 columns):\")\n",
    "print(X_train_scaled.iloc[:3, :10])\n",
    "print(\"\\nLabels (first 10):\")\n",
    "print(y_train.head(10))\n",
    "print(\"\\nSample weights (first 10):\")\n",
    "print(weights_train.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
